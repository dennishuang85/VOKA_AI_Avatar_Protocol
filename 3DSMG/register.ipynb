{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6542334c12dc43e08d260305dd6206e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [], 'layout': {'height': 600, 'template': '...'}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from Visualization import Visualization\n",
    "\n",
    "figure = go.FigureWidget()\n",
    "figure.layout['height'] = 600\n",
    "\n",
    "vision = Visualization(figure)\n",
    "\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ba59b7d4dc42cca362d3cd3b4871b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5db7a9ee2f64613ab40ae10d0be85a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaosy/anaconda3/envs/3DSMG/lib/python3.7/site-packages/pytorch3d/structures/meshes.py:1108: UserWarning:\n",
      "\n",
      "__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785b0396da2b42338160a8c3ea05f728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a9691693cf40bab76029cab433e4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13966/830668717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrg_mesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mspatial_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/spatialTrans/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrg_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/3DSMG/Algorithms/Register.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(src_head, trg_head, vision)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# print(trg_face.to_p3d(), Pointclouds([useful_new_verts]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mloss_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_mesh_face_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_face_mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_p3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPointclouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0museful_new_verts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DSMG/lib/python3.7/site-packages/pytorch3d/structures/pointclouds.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, points, normals, features)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 )\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points_per_cloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 self.valid = torch.tensor(\n\u001b[1;32m    203\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import tensor, save\n",
    "from Algorithms.Register import register\n",
    "from StylizedModel.IO.Load import load as model_load\n",
    "from StylizedModel.IO.Save import save as model_save\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "from utils import walk_file\n",
    "from StylizedModel.HeadMesh import HeadMesh\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "src_path = 'data/models/template/template.fbx'\n",
    "\n",
    "trg_file_list = walk_file('data/models/normalized/')\n",
    "trg_file_list.sort()\n",
    "\n",
    "loop_trg = tqdm(trg_file_list)\n",
    "for trg_name, trg_file in loop_trg:\n",
    "    try:\n",
    "        src_mesh = model_load(src_path ,device)\n",
    "        trg_mesh = model_load(trg_file, device)\n",
    "        spatial_trans = register(src_mesh, trg_mesh, vision)\n",
    "        save(spatial_trans, 'data/spatialTrans/' + trg_name + '.pt')\n",
    "        \n",
    "        (filepath, tempfilename) = os.path.split(trg_file)\n",
    "        model_save(trg_mesh, 'data/models/aligned/' + tempfilename)\n",
    "        \n",
    "        _src_mesh = model_load(src_path, device)\n",
    "        _src_mesh.transform_with_model(spatial_trans)\n",
    "        model_save(_src_mesh, 'data/models/registered/' + trg_name + '.fbx')\n",
    "    except Exception as e:\n",
    "        print(repr(e))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a5d355cdefba88cfab3818ac6fd804af291cb222670baa5c9998fa86bd1d2f1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
